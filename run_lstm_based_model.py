from processes import run_model

config = {"train_batch_size": 32,
          "embedding_dim": 300,
          "hidden_dim": 512,
          "dropout_rate": 0.1,
          "num_layers": 2,
          "n_epochs": 10,
          "clip": 10,
          "teacher_forcing_ratio": 0.5,
          "with_attention": True,  # only for seq2seq model
          "attention_model": 'concat',  # dot|general|concat
          "decoding_type": 'beam',  # beam|greedy|weighted_beam
          "beam_width": 4,
          "max_sentences": 3,  # number of generated sentences by beam decoding
          "max_sentence_len": 40,  # max length of a sentence generated by beam decoding
          "train_preprocess": False,  # to train preprocess, it's necessary to prepare TWITTER data before
          "with_preprocess": False,  # to train a model with preprocessed model
          "process": 'test',  # train|test|train_lm
          "is_stylized_generation": True,  # while testing generate text with different styles
          "with_stylized_lm": False,  # if "is_stylized_generation" is True
          "with_controlling_attributes": True,  # if "is_stylized_generation" is True
          "style": "funny"}

if __name__ == "__main__":
    run_model(config)
